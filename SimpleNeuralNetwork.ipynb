{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic neural network \n",
    "\n",
    "This notebook is made for learning purposes. The primary goal is to understand the underlying backpropagation algorithm that calculates the gradient of the cost function which in turn allows the network to learn. A network is created that is able to use three different activation functions and have any number of layers and units as long as memory allows it. The network is tested on the MNIST dataset and achieves an accuracy of 85% on this ten categories classification problem.  \n",
    "\n",
    "## Notation for multilayer perceptrons \n",
    "\n",
    "We denote the unit values of the $l$'th layer of a neural network in vectorform as $a^{(l)}$. The vector is given by \n",
    "\n",
    "$$a^{(l)} = \\sigma(z^{(l)})$$\n",
    "\n",
    "Where $\\sigma$ is some activation function and $z^{(l)}$ is given by \n",
    "\n",
    "$$z^{(l)} = W^{(l)}a^{(l-1)} + b^{(l)}$$\n",
    "\n",
    "Where $W^{(l)}$ and $b^{(l)}$ are the weight matrix and bias terms, respectively, corresponding to the layer below. \n",
    "As an example, if x is a vector corresponding to a single observation and the layer consists of two layers, the final activations, $a^{(2)}$, are given by\n",
    "\n",
    "$$a^{(2)} = \\sigma(W^{(2)}\\sigma(W^{(1)}x + b^{(1)}) + b^{(2)}) $$\n",
    "\n",
    "Note that $x$ is treated as $a^{(0)}$. Adding more layers means that higher orders of $a$ can be found by iteratively using the newfound activations as input to the next matrix multiplication. Finding the activations by propagating forwards like this through the network is known as feedforwarding.\n",
    "\n",
    "It is possible to expand the matrix multiplication such that more than one observation will be feedforwarded in the network at the same time. An example of this is by creating a matrix $X$ in which each row is a single observation $x_i$. If $X$ has n rows, we can find the first layer activations $A^{(1)}$ of n observations by\n",
    "\n",
    "$$A^{(1)} = \\sigma(X(W^{(1)})^T + b^{(1)})$$\n",
    "\n",
    "and we can generally find $A^{(l)}$ as \n",
    "\n",
    "$$A^{(l)} = \\sigma(A^{(l-1)}(W^{(l)})^T + b^{(l)})$$\n",
    "\n",
    "The objective is to use an algorithm known as stochastic gradient descent to iteratively improve the weights and biases of the network and thus attain better predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset\n",
    "\n",
    "We import the mnist dataset, which has 60000 images each of 28x28 pixels. Each image is a handdrawn digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of handwritten digits.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAAoCAYAAAD9lf4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGgxJREFUeJztnXtYTekex79r76LMlDTVhCTjViQcRjGxFUMcFQ25HE7jEuokpJDLOQ25dDKMPJPLoAyPoQmZTFIhmcEo5dJwUs50o1Kii2qXes8fnb2mnS577/VmmN7P86zn2Xuttb/r22qvd/32+/5+7+IIIWAwGAwGg8For4j+aAMMBoPBYDAYfyQsGGIwGAwGg9GuYcEQg8FgMBiMdg0LhhgMBoPBYLRrWDDEYDAYDAajXcOCIQaDwWAwGO0aFgwxGAwGg8Fo17BgiMFgMBgMRruGBUMMBoPBYDDaNSwYYjAYDAaD0a5RU2ZnPT09YmJiIvigmZmZKCoq4mjrAsCtW7eKCCH6tLWZZ3nedc/vwrlorM08q+65qqoK6enpGDRoUKvab4vnlmDXtjzM8+8wz/I09twshBCFl2HDhhEa/F+Hui4hhABIagtt5lmed93zu3AuGmszz6p59vDwIPr6+sTR0VEh7bfBc2u0t2v70aNHRF1dnTx48KDJ7W+j59Zgnn9HVc+zZs0iJiYmLe7T2HNzC9VhstraWhQXF6O4uBibNm3CtGnT8OTJE3AcB01NTUHat2/fRpcuXSAWiyEWi6Grq0vJddMYGhoiLS2Nmp6/vz9EIhGuXLlCTbOtKCsrQ15eHrZu3QqpVCpYLzMzE7q6uhCLxbhw4QIFh/U8fPgQqamp4DgOIpFIbqmurhakXVNTg1GjRlFyqhgrV65U+TrR0tICx3Fyy9tEeXk5jh07Bi8vL2hqamLy5MlwdXWFq6srNm7ciKSkJOrHfPjwIcRiMb7++mv4+PggIiJCsCYhBLNmzUJubi4Fh2+Go0ePYu7cuejQoQM6dOiAMWPGtPkxX758iW7duiEzM1OQzrlz56CpqYk9e/aguroapqamdAwKpKysDBUVFa3uJxaLsXnzZurHDw0Nhbq6OkQiEXbv3o1Xr15RP0ZbsG3bNmptU05ODk6dOoXMzExUVlYK1hMcDGVnZyMjIwOLFy/G7NmzoaenBz09Pfj5+SE5ORnLli2DlpYWhg8fLug49vb2KCkpAQDo6emhpKRE6RvemTNnFN5XqN/GbN++HWKx+K27STXGzc0No0ePhpGRETZu3AgfHx/Bmvr6+pBIJBTc/U5qaiomTJiAyZMnvxYEcByHpUuXorS0VGX9kpIS/Pbbb8jPz6foumX27dsHdXV1lT7bqVOn19bFxMQItUSNTZs2Yd68edi1axeqqqpw/vx5HDx4EAcPHoS/vz8sLS1hYWGB3377jdoxnz17xr82MjKiollZWYmffvoJ0dHRVPTamqKiIri4uCAqKgoTJkxAx44dcfXq1TY51pMnT3Dnzh1kZ2cjPDwcnTt3xgcffCBI09nZGRKJBF9++SUll3QICAjA/v37FdrXz8+P6rFDQ0Px7bff8u+9vb3x+PFjwbpZWVlYsWIFOI7DnDlzBOs1RVBQEDiOw6FDhwRrvXjxAjU1NQCAjh07CtYTHAyNGzcO/fr1w8GDBxEeHg5LS0vY2dmhY8eOyMrKwqlTp1BaWqryBThv3jyIxWI8efKEXxcQEACJRAIXFxeltE6fPq3Qfo8fP4auri769++vlH5zxMXFQSqVwtTUFCNGjBCkdfLkSRgaGkIkEsHW1hYWFhYQi8UQiVT/V5aUlPC9bgcOHEBVVRX++9//AgC+/vprQX6B+l6WFy9eCNZpyOXLl5GTk4OamhqsXbsWvr6+8PX15bcfOXIEd+/eFXSM/Pz8NgmGEhISUFxcLLfuu+++g7GxscrXSUFBAQYPHgxzc3N+XZ8+fQT5bIm4uDi4u7vL9cqZmZk1u/+SJUuQkZGBjIyM17qnS0tL0aNHD9y7dw/bt2+n4m/jxo2wtrZGdnY26urqMHv2bCq6nTp1wu7du5GQkEBFrzFXrlyBs7Mz1NXV+V5wsVjc4rltjtjYWBgYGKCurg7FxcU4d+4cysrKsHHjRvTq1YuK36CgIP7/37t3b+zcuRMmJiaYP38+1q9fDy0tLZW1fXx88PDhQ0RHRwtq35ri+vXrEIlEcud4/vz5Sml4e3ujS5cuzW4vLy8XapMnIiICkydPhkgkgqurK65evYpDhw7h8OHDgrWrq6uhqamJ/fv3w8/PD7du3cKJEycouJbn6tWrKCgoAAAsXLhQsJ6FhQX/msb3Q7BCYGCg3JcoLi4OUVFRSExMFCoNoL6blBACiUSCHTt2gBCCoUOHYvny5agfDqTPokWL0LdvXypaP/30Ez7//HMA9Re3hoaGylqvXr2Cq6srCgsLcfHiRVy4cAHXrl0T7PHMmTN8L0qfPn0QGxuLnj17CtaVUVFRgaysLABAYmIi/1oIbm5uyMzMREpKCrZu3Qp/f3/4+/uje/fuAICpU6fi448/FnwcGt2vjVm8eDHu378vt27Lli3Yvn07Bg8erLLuhg0bkJqayr+nMcTZFAsXLsSnn36KvXv3QltbG0uXLkVFRQUePHjQ7Gd69+7NL42JjIzkvxOLFi2i4nHHjh0wMTHhvw80GTFiBMLCwpCXl0dFLy8vD2PHjoWxsTEcHBwQHh6OoUOHyu2jyJBMY2pqappsx6ZPn46qqipBPacy1q5dC6C+bcvOzsaRI0egr6/PH0dVpFIpjh07Rq1HryFFRUVYvHgxDAwM4OrqinPnzgEAbty4obCGLJgsLS3F8+fPm9wnPT1duNn/4+TkhOjoaBBCUFtbi9raWv7+V1tbK0g7JCQE//73v7F161bo6OggJiYGH374IQ3bPJmZmfD09AQAjB8/XrDeN998I1jjNRRJLFIkqcnb25twHEdqa2tbTXpSJFkqLS2NzJ49mxgYGJDBgwc3qSMSicjs2bPl1qGZBK9t27aRuXPntuotPz+fGBoakuzsbKU9N6awsJBwHEfU1NTIxYsXm92vOc8NWb9+PeE4jixbtoyUlJTw601NTYlIJCIRERGvfUZRz48fPyY///wzKSgokFsvEomISCRS2XNjZHp79uxpdh8hyX/fffcdf4yG56gpz63pPn/+nAAgK1asaPW4ypyLDRs2EDU1NfL06VN+3axZs4hIJCLV1dWCPB89epQA4Jddu3ZR8Sxj+fLlhOM44unp2eJ+inq+ePEimT9/PgFAOnToQPbt26ewbnPaz58/J15eXkQkEpGAgAC5bV5eXsTLy0uQZ0IIyc7OJgBIUFBQi/sp6ln2ndXU1Hzt2pBtKywslFsv5Dqprq4mAMjKlStV9ixj4MCBhOM4Ul5eTh4/fkzs7e2Jrq4u2blz52v7KuPZ2tqaTJw4UeG/SRnPtra2r7Vrenp6pGvXrkp57t+/PxGJRGTIkCGkqKjotc8mJycLbkPPnDnD30NsbW1JSEgIUVNTI2pqaoQQwr/PzMxUyHNjTE1NycCBAxv7It7e3ip7buZzhOM44uvr2+T21jyXlZWRQ4cOkSVLlvDtW0ZGBv+6lWMrlECtVGl9S8i61+Li4jBhwgTBet7e3vjxxx8RFRXVYv5OTk6OQnppaWkYOHCgQsfNz88X1L0ro+F5sLW1FaS1detWdOzYEQEBAdDU1ERVVRViYmKQlZWFDRs2wNHRUWXtbt26oVu3boL8KQJpo568Y8eOYfv27Xj06BG/TtXcGxk6OjpCbTXJN998AzU1Nf7XMwCEhYWhe/fugjybmZkhIyNDbp2Dg4PKeg2pqKhAQEAAbG1tYWNjg4kTJ1LRnThxIp/4yXEcevToIVhTLBYjOTkZhBA+UXjnzp3gOA67du0CAHh5ebVJj5EqNMzriomJgbW1dZP76enpUTum0GujISNHjsT9+/cRGxuLlStXIisrC7t378ayZcsE6d64cUNumDs+Ph5jx44V6LYe2c2vqqoKGRkZOHLkCAwNDXH8+HGldEaNGoX09HTcvXsXOTk5fH7Unj17AADff/+9YK+yUYUxY8Zgz549uHnzJiwsLPj106dPh6urq8r6aWlpuHz5Mv/++PHj0NLSgre3txDbcnh5efGv//nPf6qkkZOTww+tubq6wsfHB2KxmIo/GdSCoffeew+XLl2Cjo4O3/36+PFjdO3aVSW9c+fOYezYsS02vLIvtaI07KK/c+cOYmNjkZubi5CQENTV1UFTUxNSqRQikUjwzTAiIgL37t3D6NGjERYWJkjr6dOn4DgOaWlpCAoKwtmzZ3Hjxg0+X+OLL74QpA/UD19t2rQJP/74Iwgh4DgO3bp1o1r9Rit5/N69e3BwcEB2djYA8H4BYMqUKTh79iyV4wDySbhCCA0NxYIFCwDUD7NIpVIUFxdj6tSpcHFxETz27+bmhjVr1shVlfj4+ODUqVOCdIH6axugH8x++umnSEpKQmFhIaRSKf76178CqB//z8vLg4GBgdKaoaGhSEhIwIYNG2BlZYU5c+bgxIkT0NfXx61bt1BaWorx48cjOjqa6lCwqpSVlUEikeD48eMwNDTk12/btg0bNmyAubk51QpMAHyVrLOzM4D6YaN9+/ZhxowZSudJyuZtcnJyAiEEU6ZMERwIAfU5dGZmZujVqxcCAwMxceJEaGpq4syZM7CzsxOknZ+fDw0NDXTq1Akcx+G9995Tacjw8OHDqK6uxvHjx/GXv/xFkKemuH37NkpLS1FXV8evGzBgAB8IAcD7778vaJhs06ZNkEgkKC0thZ2dHW7cuIEXL15AW1tbiHWemzdv4quvvgJQn3+qapqImZnZa+3Ps2fPYGhoSC2vk/oM1FevXuXHBDdv3qxSlvu5c+fAcVyrv2w5jsOQIUMU0tTU1MSSJUswdOhQflm3bh1/k9q7dy+Sk5OhoaEhOOLMzMyEk5MTamtr8dFHHwkef+3QoQMAwMTEBOvWrcMvv/zC/7IV+ouxpqYGN2/ehJWVFeLj4zF9+nS+TLu2tlbhpPM/gqa6OiMjIxEVFUXtGD/88AMVnYULF4LjOPTt2xeJiYmQSCQYMWIEkpKSqCRBenp64vTp0zh+/Di+/fZbao0ZUB+8cRyH2NhYapoAEBUVhaSkJERFRWHRokV8QFtXV4eZM2fK3QQUZcWKFQDqG/mCggKcPHkS2tramDFjBtTV1bF06VKMGzfurQiEAOCzzz7DpUuX5AKhyMhIbNq0CUB94nnDbUKQSqV49OgRfv75ZwDA0qVLMXToUAwbNgyBgYHYtm2b0ppXr17lr70pU6YgMjJSsM/U1FSoqdX/Trezs+PbpEWLFqnksTH379/HpUuX+PdOTk4qa61atarJalah01ykpqbCycmp1XtReXm5yverixcv8iMKFhYWuH79Ovr06UO17Th8+DAIITAzMxM0etEUH3zwAWhNzAhQ7BmSMWjQIISFhSEyMhIuLi5IT09XuhGtrKyEgYEBZs6c2eR2qVQKPz8/jBs3TuHqk+DgYLnAzNjYGL6+vrCyspLb7+nTp/joo4+U8tuYgIAA/gsqSzAUgo6ODnR1dfHs2TOsWrUKn3/+Odzd3fHkyRPMmjVLkPb58+cxbdo0+Pn5wcbGBgMGDICtrS3u3buHp0+fYu3atfD09KRSuiiL7BMSEuDh4aGyzqBBgxAfH4/CwkK5XxqHDh1CUFCQYJ+0OXnyJDp06AAdHR2cPHkSXl5euHLlCt+j1aNHD8THxzeZXKwMkyZNAlB/njMyMnDs2DFkZWWpfOP/5ZdfMHToUJw/fx5BQUGYPn06bty4oVJlU3MYGxvD2NgYkyZNgkQiwbx58wDUD4vs2LEDq1evVll72rRpAICzZ89CIpHw12RLid7K0LCahSaOjo78DdTd3V1lncrKSjx9+hTBwcG4dOkSKisr8euvv/Lbf/31VxgZGWHBggX4+9//rlKF2alTp3ivtHp+CwoK+B4qf39/fr2bm5tctaQQGrb769ato6Ipo2/fvpg8eTJ0dHRU7rX39PRUKAUkPDxcJX0AMDAwgLOzM8rLy/mesX/84x8q6zXmq6++wqFDh8BxHOLi4t5IKoYQqAdDd+/eRXh4OF9NVlRUpJKOs7Nzk0Nst2/fxrBhw+Do6Kj0PCqKDp8cO3ZMKd3GHDx4EADw/PlzvP/++4K0ZBQWFsq9T0hIAMdxKl/ItbW1WL9+Pfbu3Ys9e/bA3d0diYmJ0NfXR9++fREXF4dhw4bh2rVrMDAwQHl5OYyNjQXNAyNrLGkM3fTs2fO1m/zIkSOpB0NSqRQPHz5Ev379VNbIz8+Xq0qTBZ4nTpyAubk5jIyMqP4aW716NXbs2IHAwECVA6GuXbti/fr1sLS0hK6uLl69egUrK6s2zbWZO3cukpOT+dweVctlHR0dcfv2beTk5MDFxQXz5s1DVVUVsrOz0blzZ2p+hQavTdFw7rTdu3errDNx4kQkJCRg/PjxWLFiBezt7WFtbQ1TU1OkpaWhrKxMUNt09OhRuLi4YMuWLfDw8EDnzp2p5TURQvgqsobzFD169IjqdQIAEomE73lXhd69e2P06NEwMzPD3r175balpKTwwdDz589bLMNvjpbm4+nfvz/S09ORkpKi0nU+aNAgPHjwAIQQaGho4ObNm1QqcAEgIyODzxVSpYe3JW7evAmgfu6wVatWwcfHB4WFhaioqMCdO3dUzpWkOkyWlpYGOzs7+Pv748KFC1BTU1MpZ4gQ0uRssTt37oSNjQ3+9re/vdXDNzJoBUJtwYEDBxAYGIj9+/dj1qxZcHZ2ho2NDf71r38hNjYWNjY20NbWhp2dHfbt24dJkya9FZP41dTUNFnufvjwYWpl2TJMTU1RVVXFj3mryvLly/nXJSUlCAsLQ+/eveHs7IwBAwao3MA/e/bstaTPvLw8HDhwAICw7n9PT08sW7YMHMehf//+2LJlC7Zt20blZpSXl8cPAzXmzp07AOqTfC0tLVXSl+XUlZWV4ciRI8jNzQXHcejevTvVa5L21AUVFRUIDQ0FAMyZMwdz585VWSsmJgbXrl1DZGQkxo0bB2tra6xZswa5ubn48MMPBZ8HWZn0ypUr+bw6WkMWzfUw7d27l+85FMqDBw9gYGAAd3d3Qb61tbURHx//WiDUGGUnCCakvoS+YX6QjPLycjg5OSE9PR29e/cWNB0HUD+31Zo1a6gFQgDwn//8h5qWjAcPHsDLywuWlpawtLSEubk5ZsyYgczMTAwcOBCDBw8WNqGoIiVnzZW7EVJfin7x4kXCcRy/WFlZkdOnTzdb6tZaGV1YWBhfkigrHReJROSTTz4hGzduVKqMTtlnpwAgISEhSnsmhJCUlBTSvXt3oqGh0WwJLy3PHMcRkUgkV6KtjOchQ4bw51UkEpHAwECSnp7epp6nTp3KHy8jI0Npz4MHDyYikYh4eHgQX19ffpGdC5FIRMLDwxXyrGgpeefOnVudLkKZc9GrVy++LFYRWvJ87do1vrR00qRJREtLi39vampKzbOytHaeZR4rKioIIYRUVFQQPz8/oq2tzW+Lj49XyXNkZCSxsbHhvw+7du1qUktZzw2RSqVUS+tltFSG3ZjW2qP+/fuT+fPnEwcHBxISEkLMzMyIlZUVSU5OpuKZ4zhiY2NDwsLCCMdxxNXVVbDnhmhoaJDg4GCSnJxMQkNDSb9+/Uhubq4gzzIWL15M7Ty3RteuXfn/a3l5uVKe4+PjiZqaGl9a3/C1ra0tFc+JiYlEXV1d4b9H0fPcs2dPwnEc+f777xXSbc3zzp07+bbh8uXLTU5Doqjn5hZBw2TFxcWwtraWK2k+ffo0n/mvKiNHjuRfP3z4EADg4eEhqNtYGa5fv95kRN4aL168QEFBAYyNjdt8+ngisLInISEBERERyM3NxYIFC6hPstUUixcvppKQHBwc/No6AwMDODg44LPPPhOs35CSkhJEREQI6mVpSFZWFrVftyNHjkRwcDDc3d1x/vx5fn2XLl2o5cW0JZ988gl0dHTw4sULpKSk8Ou1tLRUfnzLlClTMGXKFFoWm0Q2rBIbG0ulcgr4/Ze0kOHYxnqampqoq6tDdHQ0HBwcqJR6N0RfX5/P65T1RtIiMDAQXl5ekEql0NbWhqenJ7Uh2qNHjzb5+Jq24OzZs7C3t0dhYSGSkpKU+l5LJBKsW7dO7tlmhoaGGDNmjMKPAmkNV1dX6kPfqampePnyJfz8/Ki1x9OmTcOFCxcwc+ZMalMsNEblYEg2nj9gwACsWbMGa9asoTY3i5GRkeBZNf8ITE1NMWrUqDfyEMeQkBAsXLgQM2fOlKuMUBQtLS1qN2VFmTRpkqD/6+3btyGVSmFkZITi4mIEBwfD0dGRWrVNY/Lz82FhYYFhw4ZR06T9vXZzc4ObmxtVzbamqqoKZ86cQW5uLn744QcMHz4cw4cPh62treCCgDeFlZUVJk+eTEUrNTUVvr6+WLJkidyQqlDaYvZ0Gdu3b8fmzZvx5ZdfYuXKldT1PTw8BBVZNEVlZSV8fHxgb2+PkydPUtVujo8//lhQ6fcXX3xBZeqUlqA5UzYAmJubo1OnTrC3t6eWVG9iYtLmzwNUORiinRT1tiCkx8XQ0PCNPZXeyckJJ06cQGxsLF6+fMnPBfNnp2PHjq8lk7cVbfF8Hkb9/1AW9NCc3O1Ncv36dWpaR48eRVRUFO7fv0/teYhtzerVqwVV+v0RhISEIDg4uE2DxHcNV1dXfhoDmtB45NKbhvo8Q4w3g7a2NqKjo1FbW9tuAiEG489IQEAAamtr35lA6F3F3d0ddXV1VKYJ+bMgZOqGPxucMj0hHMcVAqAR8vUkhPDPI6Co25bazPOb0X4jnt+RcyGnzTwzz29Aty21mec3o808t6DdHEoFQwwGg8FgMBh/NtgwGYPBYDAYjHYNC4YYDAaDwWC0a1gwxGAwGAwGo13DgiEGg8FgMBjtGhYMMRgMBoPBaNewYIjBYDAYDEa7hgVDDAaDwWAw2jUsGGIwGAwGg9GuYcEQg8FgMBiMds3/ADVe2zT5VrtZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load data. \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Display some of the images.\n",
    "print(\"Examples of handwritten digits.\")\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(1,25,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    #plt.xlabel(class_names[y_train[i]])\n",
    "\n",
    "# Reshape 2D images to flat arrays and scale pixels.    \n",
    "x_train = x_train.reshape(60000, 28*28) / 255.0 \n",
    "x_test = x_test.reshape(-1, 28*28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the network\n",
    "\n",
    "The part of the neural network that learns over time is the weights and biases. We start out with a function that creates the weights and biases. A bias vector $b^{(l)}$ has as many elements as there are units in layer $l$. A weight matrix $W^{(l)}$ maps a vector of dimension $dim(a^{(l-1)})$ to $dim(a^{(l)})$. So if for instance $dim(a^{(2)})=100$ and $dim(a^{(3)})=200$, the matrix $W^{(3)}$ has the size $[200, 100]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_weights_and_biases(input_shape, nodes):\n",
    "    \"\"\"Returns two lists. A list of all weight matrices and one\n",
    "    of all biases. The inputs are \n",
    "    \n",
    "        input_shape: a tuple (num_observations, num_features).\n",
    "        \n",
    "        nodes: is a list containing the number of \n",
    "            nodes in each layer.\"\"\"\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for l in range(len(nodes)):\n",
    "        if l == 0:\n",
    "            w = np.random.normal(size=(nodes[l], input_shape[1]))\n",
    "            b = np.random.normal(size=(nodes[l]))\n",
    "        else:\n",
    "            w = np.random.normal(size=(nodes[l], nodes[l-1]))\n",
    "            b = np.random.normal(size=(nodes[l]))\n",
    "        weights.append(w)\n",
    "        biases.append(b)\n",
    "    \n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward \n",
    "\n",
    "When running through the network to get the output it is important to save the $A^{(l)}$ and $Z^{(l)}$ matrices that are generated at each layer. These will be necessary when performing the backpropagation algorithm. Within the feedforward function we see that at each layer the calculations $Z^{(l)} = A^{(l-1)}(W^{(l)})^T + b^{(l)}$ and $A^{(l)} = \\sigma(Z^{(l)})$ are performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(x, weights, biases, sigmas):\n",
    "    \"\"\"Runs through the network.\n",
    "    Outputs the z's and a's in a list form.\n",
    "    \n",
    "        input x: matrix where each column corresponds to an observation vector.\n",
    "        input weights: the weight matrices of each layer (from 1 to L).\n",
    "        input biases: the biases of each layer (from 1 to L).\n",
    "        input sigmas: the activation functions for each layer in a list.\"\"\"\n",
    "    z_list = []\n",
    "    a_list = []\n",
    "    a = x\n",
    "    for w, b, sigma in zip(weights, biases, sigmas):\n",
    "        z = np.matmul(a, w.T) + b\n",
    "        a = sigma(z)\n",
    "        \n",
    "        z_list.append(z)\n",
    "        a_list.append(a)\n",
    "    return z_list, a_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the feedforward function we used `sigmas` as a list of activation functions. We now define the activation functions. First the *sigmoid function* which is often used and ensures that activations lie between -1 and 1.  \n",
    "\n",
    "$$ \\text{sigmoid}(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\qquad\\text{where}\\qquad\n",
    "\\text{sigmoid}'(x) = \\text{sigmoid}(x)(1 - \\text{sigmoid}(x))$$\n",
    "\n",
    "The *softmax function* approximates the argmax function in that it makes the largest value of a layer close to one while others are close to zero. This is useful for many types of classification and will be used in the final layer of this particular neural network.\n",
    "\n",
    "$$ \\text{softmax}(x_j) = \\frac{e^{x_j}}{\\sum_k e^{x_k}} \n",
    "\\qquad\\text{where}\\qquad\n",
    "\\text{softmax}'(x_j) = \\text{softmax}(x_j)(1 - \\text{softmax}(x_j))\n",
    "$$\n",
    "\n",
    "The *relu function* (rectified linear) is likely the most used activation function for so-called dense layers.\n",
    "\n",
    "$$ \\text{relu}(x) = \\text{argmax}(x,0)\n",
    "\\qquad\\text{where}\\qquad\n",
    "\\text{relu}'(x) = \n",
    "\\begin{cases} \n",
    "0 & \\text{if } x \\leq 0 \\\\\n",
    "1 & \\text{otherwise } \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, deriv=False):\n",
    "    if deriv == False:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    else:\n",
    "        return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def softmax(x, deriv=False):\n",
    "    # x is a row i this case.\n",
    "    if deriv == False:\n",
    "        softmatrix = np.zeros(x.shape)\n",
    "        for i, row in enumerate(x):\n",
    "            exps = np.exp(row)\n",
    "            softmatrix[i] = np.exp(row) / exps.sum()\n",
    "        return softmatrix\n",
    "    else:\n",
    "        return softmax(x) * (1 - softmax(x))\n",
    "    \n",
    "def relu(x, deriv=False):\n",
    "    if deriv == False:\n",
    "        x[x <= 0] = 0\n",
    "        return x\n",
    "    else:\n",
    "        x[x <= 0] = 0\n",
    "        x[x > 0] = 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function\n",
    "\n",
    "In order to tell how well the network performs we define a cost (or loss) function. The function is what the network tries to minimize by changing the weights and biases. The cost function of a single observation $x$ with m elements is denoted by $C$. \n",
    "\n",
    "$$ C = \\frac{1}{2 m} \\sum_i (a_i^{(L)} - y_i)^2 $$\n",
    "\n",
    "We can then evaluate the general loss to be the mean of all loss scores from all observations.\n",
    "\n",
    "To make the this equation work we must first change `y_train`. When we get the $y$ labels from the dataset they are, for example if there were four labels, of the form `[0, 5, 4, 9]`. In order to calculate the the loss properly we must put this into a one-hot-encoded form. The `[0, 5, 4, 9]` would then become a matrix looking like this\n",
    "\n",
    "$$\\begin{bmatrix} \n",
    "1 && 0 && 0 && 0 && 0 && 0 && 0 && 0 && 0 && 0 \\\\ \n",
    "0 && 0 && 0 && 0 && 0 && 1 && 0 && 0 && 0 && 0 \\\\\n",
    "0 && 0 && 0 && 0 && 1 && 0 && 0 && 0 && 0 && 0 \\\\\n",
    "0 && 0 && 0 && 0 && 0 && 0 && 0 && 0 && 0 && 1 \\\\\n",
    "\\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_loss(y_preds, y_targets):\n",
    "    \"\"\"Calculates the loss.\"\"\"\n",
    "    y_one_hot = one_hot(y_targets)\n",
    "    return ((y_preds - y_one_hot)**2).mean(axis=1).mean() # The last .mean() gives the mean of all observations/rows.\n",
    "\n",
    "def one_hot(y):\n",
    "    \"\"\" Create a matrix where each row corresponds to an observation\n",
    "    and has ten columns. In every row only one value is 1 and \n",
    "    the rest are zero.\"\"\"\n",
    "    y_one_hot = np.zeros((len(y),10))\n",
    "    for i, target in enumerate(y):\n",
    "        y_one_hot[i, target] = 1\n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "In order to perform the backpropagation it is useful to define the *error* $\\delta_j^{(l)}$ of unit $j$ in layer $l$ by\n",
    "\n",
    "$$\\delta_j^{(l)} = \\frac{\\partial C}{\\partial z_j^{(l)}} $$\n",
    "\n",
    "This single element $\\delta_j^{(l)}$ is a single entry of a vector $\\delta^{(l)}$ and for the sake of linear algebra can be put into a matrix, $\\Delta^{(l)}$, as a row where each row corresponds to a calculation for a particular observation $x$. If we now define $L$ to be the final layer of the neural network, each $\\Delta^{(l)}$ can be found using the formulas\n",
    "\n",
    "$$\\Delta^{(L)} = \\nabla_{a^{(L)}} C \\odot \\sigma(Z^{(L)})$$\n",
    "\n",
    "$$\\Delta^{(l)} = (\\Delta^{(l+1)} W^{(l+1)}) \\odot \\sigma'(Z^{(l)})$$\n",
    "\n",
    "These deltas are useful because of their relationship with $\\frac{\\partial C}{\\partial W}$ and therefore grants the gradient needed to perform the stochastic gradient descent algorithm.\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial b^{(l)}} = \\delta^{(l)} $$\n",
    "$$\\frac{\\partial C}{\\partial W^{(l)}} = (a^{(l-1)})^T \\delta^{(l)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(x, y, weights, biases, activations):\n",
    "    \"\"\"Calculates the gradients with respect to all weights and biases.\"\"\"\n",
    "    \n",
    "    # Prepare y and the z and a lists.\n",
    "    y = one_hot(y)\n",
    "    z_list, a_list = feedforward(x, weights, biases, activations)\n",
    "    DELTAs = []\n",
    "    \n",
    "    # Since we propagate backwards, we work with all matrices in reverse order\n",
    "    reverse_list = np.flip(list(zip(z_list, a_list, activations)), axis=0)\n",
    "    \n",
    "    for i, (z, a, activation) in enumerate(reverse_list):\n",
    "        if i == 0:                                                # Final layer, L.\n",
    "            DELTA = (a - y) * activation(z, deriv=True)           # Here dC/da is given by (a - y).\n",
    "        else:\n",
    "            DELTA = np.matmul(DELTA, weights[-i]) * activation(z, deriv=True)\n",
    "        DELTAs.insert(0, DELTA)\n",
    "    \n",
    "    # Create the gradients of C. \n",
    "    # DELTAs come in order DELTA 1, DELTA 2, ..., DELTA L-1, DELTA L.\n",
    "    a_list.insert(0, x)\n",
    "    delC_delbs = []\n",
    "    delC_delWs = []\n",
    "    BATCH_SIZE = x.shape[0] # Size of the batch feeded into the backpropagation algorithm.\n",
    "    for i, DELTA in enumerate(DELTAs):\n",
    "        delC_delb = np.zeros((BATCH_SIZE, biases[i].shape[0]))\n",
    "        delC_delW = np.zeros((BATCH_SIZE, weights[i].shape[0], weights[i].shape[1]))\n",
    "        for j, delta in enumerate(DELTA):\n",
    "            delC_delb[j] = delta\n",
    "            delC_delW[j] = np.matmul(delta.reshape(-1, 1), a_list[i][j].reshape(1, -1))\n",
    "        delC_delbs.append(delC_delb.mean(axis=0)) # Calculate the mean of the biases for all observations in batch.\n",
    "        delC_delWs.append(delC_delW.mean(axis=0)) # Calculate the mean of the weights for all observations in batch. \n",
    "    \n",
    "    return delC_delWs, delC_delbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Training the network works with the help of stochastic gradient descent. Any weight $w_{ij}^{(l)}$ can be iteratively updated by using a forward pass followed by a backward pass to gain the gradient $\\nabla_w C$. The weights $w$ are updated with\n",
    "\n",
    "$$ w := w + \\eta \\nabla_w C$$\n",
    "\n",
    "Where $\\eta$ is a scaler called the *learning rate*. This process is known as stochastic gradient descent and is a simple algorithm for updating the weights and biases. Each time a gradient has been computed and the weights updated is called an epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(x, y, nodes=[100, 100, 10], activations=[sigmoid, sigmoid, softmax], \n",
    "          learning_rate=10, batch_size=128, epochs=5, validation_data=None):\n",
    "    \"\"\"Do some training.\"\"\"\n",
    "    \n",
    "    # Create the weights and biases\n",
    "    weights, biases = create_weights_and_biases(input_shape=x.shape, nodes=nodes)\n",
    "    \n",
    "    # Calculate the number of batches.\n",
    "    num_runs = int(x.shape[0] / batch_size + 1)\n",
    "    accs, losses, val_accs, val_losses = [], [], [], []\n",
    "    \n",
    "    # Start the loop. \n",
    "    for i in range(epochs):\n",
    "        print(\"Epoch \", str(i + 1))\n",
    "        \n",
    "        # Perform this operation for each batch.\n",
    "        for j in range(num_runs):\n",
    "            if (j+1)*batch_size <= x_train.shape[0]:\n",
    "                x_batch = x[j*batch_size:(j+1)*batch_size]\n",
    "                y_batch = y[j*batch_size:(j+1)*batch_size]\n",
    "            else:\n",
    "                x_batch = x[j*batch_size:]\n",
    "                y_batch = y[j*batch_size:]\n",
    "            \n",
    "            # Get the changes in weights and biases.\n",
    "            delC_delW, delC_delb = backpropagation(x_batch, y_batch, weights, biases, activations)\n",
    "            \n",
    "            # Update the weights and biases.\n",
    "            for k in range(len(weights)):\n",
    "                weights[k] = weights[k] - (learning_rate * x_batch.shape[0] / x.shape[0] )*delC_delW[k]\n",
    "                biases[k] = biases[k] - (learning_rate * x_batch.shape[0] / x.shape[0])*delC_delb[k]\n",
    "        \n",
    "        # Calculate accuracy and loss.\n",
    "        z_list, a_list = feedforward(x, weights, biases, activations)\n",
    "        preds = predictions(a_list[-1])\n",
    "        acc = accuracy_score(preds, y)\n",
    "        loss = simple_loss(a_list[-1], y)\n",
    "        \n",
    "        # Calculate the validation accuracy and loss. \n",
    "        if not validation_data:\n",
    "            val_acc = \"not computed.\"\n",
    "            val_loss = \"not computed.\"\n",
    "        else:\n",
    "            x_val = validation_data[0]\n",
    "            y_val = validation_data[1]\n",
    "            val_z_list, val_a_list = feedforward(x_val, weights, biases, activations)\n",
    "            val_preds = predictions(val_a_list[-1])\n",
    "            val_acc = accuracy_score(val_preds, y_val)\n",
    "            val_loss = simple_loss(val_a_list[-1], y_val)\n",
    "        \n",
    "        # Create lists of the accuracies and losses.\n",
    "        accs.append(acc)\n",
    "        losses.append(loss)\n",
    "        val_accs.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(\"Accuracy: \" + str(acc))\n",
    "        print(\"Loss: \" + str(loss))\n",
    "        print(\"Validation accuracy: \" + str(val_acc))\n",
    "        print(\"Validation loss: \" + str(val_loss))\n",
    "        \n",
    "    return accs, losses, val_accs, val_losses\n",
    "\n",
    "def predictions(y_preds):\n",
    "    \"\"\"Calculates the predictions where the input\n",
    "    is the list of a's.\"\"\"\n",
    "    preds=[]\n",
    "    for probs in y_preds:\n",
    "        pred = probs.argmax()\n",
    "        preds.append(pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we are able to train the network and see the results. During testing it seemed that a learning rate of 130 seemed to be a close to optimal choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "Accuracy: 0.3171833333333333\n",
      "Loss: 0.08110004763165429\n",
      "Validation accuracy: 0.3158\n",
      "Validation loss: 0.08115256676979106\n",
      "Epoch  2\n",
      "Accuracy: 0.48568333333333336\n",
      "Loss: 0.06623017644285821\n",
      "Validation accuracy: 0.488\n",
      "Validation loss: 0.06618688877139577\n",
      "Epoch  3\n",
      "Accuracy: 0.5873833333333334\n",
      "Loss: 0.05539197636159196\n",
      "Validation accuracy: 0.5966\n",
      "Validation loss: 0.05507492321770609\n",
      "Epoch  4\n",
      "Accuracy: 0.6491166666666667\n",
      "Loss: 0.04779592135601581\n",
      "Validation accuracy: 0.6568\n",
      "Validation loss: 0.04737912422609657\n",
      "Epoch  5\n",
      "Accuracy: 0.694\n",
      "Loss: 0.042056368900066095\n",
      "Validation accuracy: 0.7016\n",
      "Validation loss: 0.04140257277374549\n",
      "Epoch  6\n",
      "Accuracy: 0.7291833333333333\n",
      "Loss: 0.03776973582559614\n",
      "Validation accuracy: 0.7413\n",
      "Validation loss: 0.03688982780860543\n",
      "Epoch  7\n",
      "Accuracy: 0.75515\n",
      "Loss: 0.03450708486967532\n",
      "Validation accuracy: 0.7663\n",
      "Validation loss: 0.033499956583639696\n",
      "Epoch  8\n",
      "Accuracy: 0.7743666666666666\n",
      "Loss: 0.032007437172935464\n",
      "Validation accuracy: 0.7834\n",
      "Validation loss: 0.03096305306621699\n",
      "Epoch  9\n",
      "Accuracy: 0.7894666666666666\n",
      "Loss: 0.030037649725415658\n",
      "Validation accuracy: 0.7995\n",
      "Validation loss: 0.0290055217111483\n",
      "Epoch  10\n",
      "Accuracy: 0.8017333333333333\n",
      "Loss: 0.028432799411189112\n",
      "Validation accuracy: 0.8108\n",
      "Validation loss: 0.027439883338782816\n",
      "Epoch  11\n",
      "Accuracy: 0.8115166666666667\n",
      "Loss: 0.027088870696203138\n",
      "Validation accuracy: 0.82\n",
      "Validation loss: 0.026152128369040822\n",
      "Epoch  12\n",
      "Accuracy: 0.81995\n",
      "Loss: 0.02593863317676486\n",
      "Validation accuracy: 0.8297\n",
      "Validation loss: 0.02507009575517451\n",
      "Epoch  13\n",
      "Accuracy: 0.8272833333333334\n",
      "Loss: 0.024937607035021455\n",
      "Validation accuracy: 0.8358\n",
      "Validation loss: 0.024144891814487448\n",
      "Epoch  14\n",
      "Accuracy: 0.8339333333333333\n",
      "Loss: 0.024055497798203897\n",
      "Validation accuracy: 0.8412\n",
      "Validation loss: 0.023341556940884464\n",
      "Epoch  15\n",
      "Accuracy: 0.8404\n",
      "Loss: 0.02327036650584951\n",
      "Validation accuracy: 0.8443\n",
      "Validation loss: 0.02263443215045276\n",
      "Epoch  16\n",
      "Accuracy: 0.8452666666666667\n",
      "Loss: 0.022565541616698014\n",
      "Validation accuracy: 0.8469\n",
      "Validation loss: 0.022004969060493977\n",
      "Epoch  17\n",
      "Accuracy: 0.8501833333333333\n",
      "Loss: 0.02192800380016058\n",
      "Validation accuracy: 0.8517\n",
      "Validation loss: 0.021439944210000336\n",
      "Epoch  18\n",
      "Accuracy: 0.85405\n",
      "Loss: 0.021347372267920287\n",
      "Validation accuracy: 0.8557\n",
      "Validation loss: 0.020929556113902938\n",
      "Epoch  19\n",
      "Accuracy: 0.8577833333333333\n",
      "Loss: 0.020815440968808396\n",
      "Validation accuracy: 0.8586\n",
      "Validation loss: 0.02046601021123131\n",
      "Epoch  20\n",
      "Accuracy: 0.8618333333333333\n",
      "Loss: 0.02032588995358458\n",
      "Validation accuracy: 0.8624\n",
      "Validation loss: 0.0200429270970196\n",
      "Epoch  21\n",
      "Accuracy: 0.8651833333333333\n",
      "Loss: 0.019873472730526736\n",
      "Validation accuracy: 0.8655\n",
      "Validation loss: 0.019655020124800505\n",
      "Epoch  22\n",
      "Accuracy: 0.8684833333333334\n",
      "Loss: 0.01945359154014374\n",
      "Validation accuracy: 0.8677\n",
      "Validation loss: 0.019297841561194927\n",
      "Epoch  23\n",
      "Accuracy: 0.87165\n",
      "Loss: 0.019062440631130627\n",
      "Validation accuracy: 0.8707\n",
      "Validation loss: 0.018967683318983394\n",
      "Epoch  24\n",
      "Accuracy: 0.8745333333333334\n",
      "Loss: 0.018696913238655563\n",
      "Validation accuracy: 0.8731\n",
      "Validation loss: 0.01866146093393892\n",
      "Epoch  25\n",
      "Accuracy: 0.8772833333333333\n",
      "Loss: 0.018354384863573145\n",
      "Validation accuracy: 0.8755\n",
      "Validation loss: 0.018376569985887898\n"
     ]
    }
   ],
   "source": [
    "X = x_train\n",
    "y = y_train\n",
    "\n",
    "acc, loss, val_acc, val_loss = train(X, y, learning_rate=130, epochs=25, validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f16463db978>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xl4U2X2wPHvKVvZQUBBkBbBBShtKRVFUXBDcFQUYQRBBUQG93EZRdERmcEFUXBhHFFB1I6IOij6Q3HDBZ1R9iowCEqBAiIUKLtQOL8/3rSkJWmTJmna5nye5z5Jbt57894G7sm7i6pijDHGlCQu2hkwxhhTMVjAMMYYExALGMYYYwJiAcMYY0xALGAYY4wJiAUMY4wxAbGAYYwxJiAWMEzME5EvRGS7iNSIdl6MKc8sYJiYJiKJwNmAApeV4edWLavPMiZcLGCYWHct8F/gFeC6/J0iUlNEnhSRtSKSKyLzRKSm572uIvKtiOwQkfUiMtiz/wsRGeZ1jsEiMs/rtYrIzSKyCljl2fe05xw7RWShiJztlb6KiNwvIj+LyC7P+yeIyCQRedL7IkTkfRH5cyT+QMbks4BhYt21QIZnu0hEjvPsHw90As4EjgHuAQ6LSEvgQ+BZoAmQCiwJ4vMuB04H2nlez/ec4xjgX8BbIhLvee9OYABwMVAPGArsBaYBA0QkDkBEGgPnA28Ec+HGBMsCholZItIVSABmqOpC4Gfgas+NeChwu6puUNVDqvqtqv4ODAQ+VdU3VPWgquaoajAB41FV3aaq+wBU9XXPOfJU9UmgBnCKJ+0w4AFVXanOUk/a74FcXJAA6A98oaqbQ/yTGFMsCxgmll0HfKyqWz2v/+XZ1xiIxwWQok7wsz9Q671fiMhdIrLCU+21A6jv+fySPmsaMMjzfBDwWgh5MiYg1vBmYpKnPeKPQBUR+dWzuwbQAGgG7AdaA0uLHLoe6OzntHuAWl6vm/pIUzA9tKe94l5cSWGZqh4Wke2AeH1Wa+BHH+d5HfhRRFKAtsC7fvJkTNhYCcPEqsuBQ7i2hFTP1hb4GteuMQV4SkSO9zQ+d/F0u80ALhCRP4pIVRFpJCKpnnMuAfqISC0RaQNcX0Ie6gJ5wBagqoj8FddWke8l4G8icpI4ySLSCEBVs3HtH68B7+RXcRkTSRYwTKy6DpiqqutU9df8DXgO104xEvgBd1PeBjwOxKnqOlwj9F2e/UuAFM85JwAHgM24KqOMEvIwB9eA/hOwFleq8a6yegqYAXwM7AReBmp6vT8N6IBVR5kyIraAkjEVk4icg6uaSlTVw9HOj6n8rIRhTAUkItWA24GXLFiYsmIBw5gKRkTaAjtwjfMTo5wdE0OsSsoYY0xArIRhjDEmIJVmHEbjxo01MTEx2tkwxpgKZeHChVtVtUkgaStNwEhMTGTBggXRzoYxxlQoIrI20LRWJWWMMeVARgYkJkJcnHvMKGkUTymPCYUFDGOMKUGkb+YZGTB8OKxdC6rucfjw8B8TqkrTSyo9PV2tSsqY2JKRAaNGwbp10LIljB0LAweG95j8G/PevUf21aoFkyf7P664Y66+Gg4cgP374fff3WOXLrBx49HnadwYJkwonDZ/e+YZ2Lnz6GMSEiArq/i/gTcRWaiq6QGltYBhjCkvgrmZh+tGXrMmPPYY/OEP7qZcdBs0CLZsOfpc9evDDTe4c+3b5x7zn3/9tTu2KBFXGghVcecRgcNBDOW0gGGMCato/ZKvWRPGj4eLLoLdu922a5d7HDECcnKOPk/t2i59/g3ce1u3LribaUlq1nRBqlatws+//db/MQ8+CPHxR7YaNeDee31fS7Nm8NVXLo33MVWrQqtWrhqqKCthBMAChjGBC9cv+f793Q3ce9u9Gz74AP7xD1f1kq9qVTjvPPd5+b/IvR+XLIGDB8Nzfe3bH7l5e2+vFTNN47Rp7sZcdOvbF3799ej0LVv6vmGDa7MI5mYe7mqvkoK5t2ACBqpaKbZOnTqpMbHo9ddVExJURdzj66+XnL5mTVVXqeG2GjVUR45Ufftt1ZdeUn3ySdUHH1S97TbV2rULp83fRHzvL26Li1M9/njV1q1VO3RQ7dxZtVs31V69ij9u2jTVd95R/fhj1W+/Vc3MdOfxlTYhwf+1JyQEf8zrr6vWqlU4fa1axf+dS3tMMN9jaY8pCligAd5nrYRhTDny2mtw//2Qne2qI0aMgG7dfFev7N0L338Ps2dDXt6Rc8TFQdu20KCB++W+f/+Rx/37YceOwOrRRaBePcjN9Z/m4Yehbt2jt3PO8X9Of1VC5flXeVlUyUWLVUkZE2UHD7o66VdegYkTYfNmOOYYV7feqhVs2wbbtx953L7dVXvs2ROez69RA7p2dfXdNWseqfuuWROefdb/cUuXukBTv7678ed3CQ22rrw0x5Q2AFTWG3lZsYBhTJgdPgyTJrmbS/7N//zzoUUL2LrVbTk5R5776u6YLy4OGjWChg3deRo2dNv777s2gKKOOw7ee893nXyNGr5LC7H0S96ExgKGMSUoemMaM8ZVo6xd626aa9ce/dy72idfjRrQtKnrL9+okXvM3yZOdCWIovw1lsbFRf7mn3/t9kve5LOAYUwRubnuxrVuHbzzjmsr8BUAvDVt6m68iYnw4YfBD5IKNgCU1c0//zi7mRuoAL2kgJ7ASmA1MNLH+y2BucBiIBO4uKRzWi+p2HX4sOqzz6oed5zrjdKggep557meN+3bq9arF1gPnmOOcb1wVq5U3bev8Gf46xEk4j9fwfbIKU3PmvzjQu0pY2IX5bmXlIhUwS16fyGQDcwHBqjqcq80k4HFqvq8iLQDZqtqYnHntRJG5abqpk5YvRpWrSr8uHKl71G1iYmQmgonnOB+Rbds6Z6feabvz6ioVT/GhCKYEkY0pjfvDKxW1V8ARGQ60BtY7pVGgXqe5/UBH7OsmMro0CF48kkYN841Iteq5doGtm51XUPzVasGJ54IJ50Ea9b4DhiqMHPm0fsTEnzf/Fu29J+vsWN93/zHjvV/TP6NPpgAMHCgBQhTfkUjYDQH1nu9zgZOL5JmNPCxiNwK1AYu8HUiERkODAdoWdz/dlMuHT7sSggLFhzZvv++8M1/7143dqBHD7j0Uhcg2rRxN98qVVyaOD9zLq9b53t/Wd3884+zAGAqi2gEDPGxr2i92ADgFVV9UkS6AK+JSJKqFqowUNXJwGRwVVIRya0JSX4Vy9q1cPzx0KePGwuwYAEsXHikITk+Hjp2hOrVjy4tHD4MK1a4hmdf/PU68vcbwm7+xpRONAJGNnCC1+sWHF3ldD2uYRxV/Y+IxAONgd/KJIcmZDk5bgbQiROP9EbauBGee87NKdSxo7v5pqe7rV07tz/Y0gKUvsRgN39jghONgDEfOElEWgEbgP7A1UXSrAPOB14RkbZAPOBjgmFTHhw44CaO++67I9vq1f7TH3+8q3ryJdjSApS+xGCMCU6Zr7inqnnALcAcYAUwQ1WXicgYEbnMk+wu4AYRWQq8AQzWsu7OZXzKyHCjm/PnGTrpJPd4+ulw223w+efQoYMrXfizfr3/98aOdaUDbyWVFsAFh6wsV32VlWXBwphIsIF7pkSqbo6hMWPg3XcLD0aLi4OePWHIEBc08oMJlK4rKljXUmPKUnnvVmsqgEOH4JtvXLfUd9/1f4M/fBiWLXNrBhRVmrYFsPYFY8qrMq+SMuXX/v1u4Zthw9zU2t26uUVw2reHl17yf5y/BumBA90gtYQEV+pISAh+cRdjTPlhVVIxbudO+L//cyWJDz90q6XVrevWN77iCujVy72G0lcxGWPKL6uSMiXasQOGDj3SJhEX50oU99wD557rZmEtqrRVTMaYysGqpGLMjh0wejQ0b+5KFfkFzMOHXXfYnBzfwQKsismYWGdVUjFixw54+mmYMMFN9V2zZuG5mfJZ9ZIxsSWYKikrYVRyO3a4dZcTE13J4rzzYPFi18DtS3Ejqo0xsS2kgCEit4hIw3BlxoRPbq4bN9GqlQsU554LixbBv//tpvz2N3La5nA0xvgTagmjKTBfRGaISE8R8TWxoCkDGRmuFCECDRq46Tceegi6d3eBYuZMN39TvtKOqDbGxK6QAoaqPgCcBLwMDAZWicgjItI6DHkzAcrIgBtuONLlNTfXzfj6978fHSjyWQO2MSZYYWn0FpEUYAhuhtm5wBnAJ6p6T8gnD1CsNnqrwrHHugWGirIGbGNMScqs0VtEbhORhcA44Bugg6reCHQCrgzl3KZk8+fD2Wf7DhZgDdjGmPAKtQ2jMdBHVS9S1bdU9SCAZ6GjS0LOnfEpOxuuuQY6d3bTiB9zjO901oBtjAmnUAPGbGBb/gsRqSsipwOo6ooQz22K2L0b/vpXOPlkeOstuO8+WLUKnnnGGrCNMZEXasB4Htjt9XqPZ58Jo8OH4ZVXXKD429+gd29YuRIeecTN82QN2MaYshDqXFLivbCRqh4WEZufKgy818KuXt2tanf66fDOO9Cly9HpbUpwY0ykhVrC+MXT8F3Ns90O/BKOjMWyot1kDxxwQeOWW3wHC2OMKQuhBowRwJm4tbmzgdOB4aFmKtbdddfR8zwdOAAPPBCd/BhjDIRYJaWqvwH9w5SXmHf4MIwfD5s3+37fuskaY6IppIAhIvHA9UB7ID5/v6oODTFfMWfbNrjuOrfiXa1ahdecyGfdZI0x0RRqldRruPmkLgK+BFoAu0LNVKz5/ntIS4M5c+DZZ+GFF6ybrDGm/Ak1YLRR1QeBPao6DfgD0CH0bMUGVRcgunZ1r7/5xjVsDxpk3WSNMeVPqF1gD3oed4hIEvArkBjiOWPCzp0wbJgbgHfJJTBtWuER29ZN1hhT3oRawpjsWQ/jAWAWsBx4vKSDPFOhrxSR1SIy0k+aP4rIchFZJiL/CjGf5crSpZCe7tamGDcO3nvP//QexhhTXpS6hCEiccBOVd0OfAWcGOBxVYBJwIW4rrjzRWSWqi73SnMScB9wlqpuF5FjS5vP8kQVpkxx1U7HHANz57rJA40xpiIodQnDM8HgLaU4tDOwWlV/UdUDwHSgd5E0NwCTPMEov/tuhZWR4Xo4xcW5aqjWrd0yqRYsjDEVSahVUp+IyN0icoKIHJO/lXBMc2C91+tszz5vJwMni8g3IvJfEenp60QiMlxEFojIgi1btpT+KiIof9T2eq8r/uUX+OST6OXJGGNKI9SAMRS4GVcltdCzlbSKka9lXIuu4lQVt5Jfd2AA8JKINDjqINXJqpququlNmjQJMutlY9Soo0dt79vn9htjTEUS6kjvVqU4LBs4wet1C2CjjzT/9ayvsUZEVuICyPxSZTSK8ueDKspGbRtjKppQR3pf62u/qr5azGHzgZNEpBVuDqr+wNVF0ryLK1m8IiKNcVVUFW5Sw40bXbvF4cNHv2ejto0xFU2o4zBO83oeD5wPLAL8BgxVzRORW4A5QBVgiqouE5ExwAJVneV5r4eILAcOAX9R1ZwQ81qmDh1yq+JVq+YG3+3ff+Q9G7VtjKmIQq2SutX7tYjUx00XUtJxs3Gr9Xnv+6vXcwXu9GwV0uOPw+efw8svQ40ars1i3TpXshg71gblGWMqnnAvdrQX19YQ07791i2l2r8/DBniShgWIIwxFV2obRjvc6SHUxzQDpgRaqYqsh074OqrXUnin/90wcIYYyqDUEsY472e5wFrVTU7xHNWWKowfDhs2ADz5kH9+tHOkTHGhE+oAWMdsElV9wOISE0RSVTVrJBzVgG99JKbTPCxx9z628YYU5mEOnDvLcC70+ghz76Ys3w53H47XHgh/OUv0c6NMcaEX6gBo6pnPigAPM+rh3jOCmffPrjqKqhbF1591Y29MMaYyibUKqktInKZZ+wEItIb2Bp6tiqWu++GH3+Ejz6Cpk2jnRtj4ODBg2RnZ7PfewCQiWnx8fG0aNGCatWqlfocoQaMEUCGiDzneZ0N+Bz9XVnNnAn/+IcLGhddFO3cGONkZ2dTt25dEhMTEeuqF/NUlZycHLKzs2nVqjQzOjmhDtz7GThDROoAoqoxtZ73unVw/fVuMSQbuW3Kk/3791uwMAVEhEaNGhHqrN4h1baLyCMi0kBVd6vqLhFpKCJ/DylHFURenhuMd/AgvPEGVI+5lhtT3lmwMN7C8e8h1ObZXqq6I/+FZ8Gji0M8Z7mWkQGJiW6OqHnz3HxRbdpEO1fGGBN5oQaMKiJSI/+FiNQEahSTvkLLyHAD87ynLJ82ze03xjg5OTmkpqaSmppK06ZNad68ecHrAwcOlHwCYMiQIaxcubLYNJMmTSLD/vOVKXHz/JXyYJF7gMuAqZ5dQ4BZqjouDHkLSnp6ui5YUNLaTaFJTPS9vkVCAmRlRfSjjQnKihUraNu2bcDpMzIiM0Hm6NGjqVOnDnfffXeh/aqKqhIXY33Q8/LyqFo13FP4Bc7XvwsRWaiq6YEcH9K35QkMfwfa4uaR+ghICOWc5Zm/RY9sMSRTkXmXnFXd4/Dh4S85r169mqSkJEaMGEFaWhqbNm1i+PDhpKen0759e8aMGVOQtmvXrixZsoS8vDwaNGjAyJEjSUlJoUuXLvz2228APPDAA0ycOLEg/ciRI+ncuTOnnHIK3377LQB79uzhyiuvJCUlhQEDBpCens6SJUuOyttDDz3EaaedVpC//B/SP/30E+eddx4pKSmkpaWR5fll+Mgjj9ChQwdSUlIY5Vk+Mz/PAL/++ittPHXVL730Ev379+eSSy6hV69e7Ny5k/POO4+0tDSSk5P54IMPCvIxdepUkpOTSUlJYciQIezYsYMTTzyRvLw8AHbs2EGrVq04dOhQ2L6XoORH+tJuQCowDsgC5gK3hHrO0mydOnXSSEtIUHX/pQpvCQkR/2hjgrJ8+fKA00by3/VDDz2kTzzxhKqqrlq1SkVEv//++4L3c3JyVFX14MGD2rVrV122bJmqqp511lm6ePFiPXjwoAI6e/ZsVVW944479NFHH1VV1VGjRumECRMK0t9zzz2qqvree+/pRRddpKqqjz76qN50002qqrpkyRKNi4vTxYsXH5XP/HwcPnxY+/fvX/B5aWlpOmvWLFVV3bdvn+7Zs0dnzZqlXbt21b179xY6Nj/PqqqbNm3S1q1bq6rqiy++qC1bttRt27apquqBAwd0586dqqq6efNmbdOmTUH+TjnllILz5T8OGjRI33//fVVVnTRpUsF1loavfxe4dYgCus+WqoQhIieLyF9FZAXwHLAeV711rqo+V8LhFdbNNx+9zxZDMhVdWZacW7duzWmnHVl37Y033iAtLY20tDRWrFjB8uXLjzqmZs2a9OrVC4BOnToV/Movqk+fPkelmTdvHv379wcgJSWF9u3b+zz2s88+o3PnzqSkpPDll1+ybNkytm/fztatW7n00ksBN/CtVq1afPrppwwdOpSaNWsCcMwxx5R43T169KBhw4aA+5F+7733kpycTI8ePVi/fj1bt27l888/56qrrio4X/7jsGHDmDrV1fpPnTqVIUOGlPh5kVLaKqn/4VbXu1RVu6rqs7h5pCq1n35yvaNatHDTlickwOTJttaFqdj8LRcciWWEa9euXfB81apVPP3003z++edkZmbSs2dPnyPTq3v1Wa9SpUpB9UxRNWrUOCqNBtBGu3fvXm655RZmzpxJZmYmQ4cOLciHr66oqupzf9WqVTnsWY+56HV4X/err75Kbm4uixYtYsmSJTRu3Jj9+/f7PW+3bt346aefmDt3LtWqVePUU08t8ZoipbQB40rgV2CuiLwoIucDlbrT96ZNbp6oYcNg/Xq3TndWlgULU/GNHetKyt7KouS8c+dO6tatS7169di0aRNz5swJ+2d07dqVGTPcEj0//PCDzxLMvn37iIuLo3HjxuzatYt33nkHgIYNG9K4cWPef/99wAWBvXv30qNHD15++WX27dsHwLZt2wBITExk4cKFALz99tt+85Sbm8uxxx5L1apV+eSTT9iwYQMAF1xwAdOnTy84X/4jwKBBgxg4cGBUSxdQyoChqjNV9SrgVOAL4A7gOBF5XkR6hDF/5cYzz7jBendW2EVjjfFt4EBXUk5IKNuSc1paGu3atSMpKYkbbriBs846K+yfceutt7JhwwaSk5N58sknSUpKon6RhWoaNWrEddddR1JSEldccQWne61NkJGRwZNPPklycjJdu3Zly5YtXHLJJfTs2ZP09HRSU1OZMGECAH/5y194+umnOfPMM9m+fbvfPF1zzTV8++23pKen89Zbb3HSSW6R0uTkZO655x7OOeccUlNT+YvXtNcDBw4kNzeXq666Kpx/nqCF1K220IlEjgH6AVep6nlhOWkQItmtdudOVzzv0QNmxPR6gqaiCLZbbWWVl5dHXl4e8fHxrFq1ih49erBq1aqodm0tjenTpzNnzpyCtozSCrVbbdj+aqq6DXjBs1UqL74Iubm2zoUxFc3u3bs5//zzycvLQ1V54YUXKlywuPHGG/n000/56KOPop2V8AWMyurAAZg4Ebp3B6/OHcaYCqBBgwYF7QoV1fPPPx/tLBSwgFGC6dMhO9vV6RpjTCyLyrh8EekpIitFZLWIjCwmXV8RUREJqH4t3FRh3DhISoKePaORA2OMKT/KvIQhIlWAScCFuAWX5ovILFVdXiRdXeA24LuyzmO+Dz+EZctcd1qbKdoYE+uiUcLoDKxW1V/UrQE+HejtI93fcFOORG2NyXHj4IQTwDNQ1BhjYlo0AkZz3FQi+bI9+wqISEfgBFX9gGKIyHARWSAiC0JdSaqo77+HL7+EO+5wo7uNMYHr3r37UQPxJk6cyE033VTscXXq1AFg48aN9O3b1++5S+pCP3HiRPbu3Vvw+uKLL2bHjh3FHGECEY2A4atyp2AwiIjEAROAu0o6kapOVtV0VU1v0qRJGLMITzwB9eu7kd3GmOAMGDCA6dOnF9o3ffp0BgwYENDxxx9/fLGjpUtSNGDMnj2bBg0alPp8ZU1VC6YZKU+iETCygRO8XrcANnq9rgskAV+ISBZwBjCrLBu+V6+Gd96Bm26CunXL6lONqTz69u3LBx98wO+//w5AVlYWGzdupGvXrgVjI9LS0ujQoQPvvffeUcdnZWWRlJQEuKk7+vfvT3JyMldddVXBlBzgxijkT4/+0EMPAfDMM8+wceNGzj33XM4991zATduxdetWAJ566imSkpJISkoqmB49KyuLtm3bcsMNN9C+fXt69OhR6HPyvf/++5x++ul07NiRCy64gM2bNwNuvMeQIUPo0KEDycnJBdOLfPTRR6SlpZGSksL5558PuDVCxo8fX3DOpKQksrKyCvJw0003kZaWxvr1631eH8D8+fM588wzSUlJoXPnzuzatYuzzz670NTtZ511FpmZmUF9byUKdFrbcG24hvZfgFZAdWAp0L6Y9F8A6SWdN5zTm48YoVq9uuqmTWE7pTFlynsa69tvV+3WLbzb7beXnIeLL75Y3333XVV104zffffdquqmMs/NzVVV1S1btmjr1q318OHDqqpau3ZtVVVds2aNtm/fXlVVn3zySR0yZIiqqi5dulSrVKmi8+fPV9UjU4Dn5eVpt27ddOnSpaqqmpCQoFu2bCnIS/7rBQsWaFJSku7evVt37dql7dq100WLFumaNWu0SpUqBdOT9+vXT1977bWjrmnbtm0FeX3xxRf1zjvvVFXVe+65R2/3+qNs27ZNf/vtN23RooX+8ssvhfLqPeW7qmr79u11zZo1umbNGhUR/c9//lPwnq/r+/3337VVq1YF08Tn5ubqwYMH9ZVXXinIw8qVK9XXPTEq05uHGKDygFuAOcAKYIaqLhORMSJyWVnnp6jNm2HqVLjuOmjaNNq5Mabi8q6W8q6OUlXuv/9+kpOTueCCC9iwYUPBL3VfvvrqKwYNGgS4+ZaSk5ML3psxYwZpaWl07NiRZcuW+Zxc0Nu8efO44oorqF27NnXq1KFPnz58/fXXALRq1YrU1FTA/zTq2dnZXHTRRXTo0IEnnniCZcuWAfDpp59ys9f6Bw0bNuS///0v55xzDq1atQICmwY9ISGBM844o9jrW7lyJc2aNSuYJr5evXpUrVqVfv368cEHH3Dw4EGmTJnC4MGDS/y8YEVl4J6qzgZmF9n3Vz9pu5dFnvI995wb3X1XiS0oxlQMnlqXMnf55Zdz5513smjRIvbt20daWhrgJvTbsmULCxcupFq1aiQmJvqc1tybr2m/16xZw/jx45k/fz4NGzZk8ODBJZ5Hi5k7L396dHBTpPuqkrr11lu58847ueyyy/jiiy8YPXp0wXmL5tHXPig8DToUngrdexp0f9fn77y1atXiwgsv5L333mPGjBkldgwojdhaULcEu3fDpEnQuzecckq0c2NMxVanTh26d+/O0KFDCzV250/vXa1aNebOncvatWuLPc8555xDhme92B9//LGgXn7nzp3Url2b+vXrs3nzZj788MOCY+rWrcuuXbt8nuvdd99l79697Nmzh5kzZ3L22WcHfE25ubk0b+46dU6bNq1gf48ePXjuuSNrx23fvp0uXbrw5ZdfsmbNGqDwNOiLFi0CYNGiRQXvF+Xv+k499VQ2btzI/PnzAdi1a1fB+h/Dhg3jtttu47TTTguoRBMsCxhepkyB7dvhnnuinRNjKocBAwawdOnSglXvwE3VvWDBAtLT08nIyChxQaAbb7yR3bt3k5yczLhx4+jcuTPgVtDr2LEj7du3Z+jQoYWmRx8+fDi9evUqaPTOl5aWxuDBg+ncuTOnn346w4YNo2PHjgFfz+jRo+nXrx9nn302jRs3Ltj/wAMPsH37dpKSkkhJSWHu3Lk0adKEyZMn06dPH1JSUgqmJr/yyivZtm0bqampPP/885x88sk+P8vf9VWvXp0333yTW2+9lZSUFC688MKCUkqnTp2oV69exNbNCNv05tEW6vTmBw9CmzZuGnNPlaYxFZZNbx6bNm7cSPfu3fnf//5HXNzR5YFQpze3EobHW2+5NYytdGGMqYheffVVTj/9dMaOHeszWIRDzAeMjAy3wtjAgW5Etw0GNcZURNdeey3r168hgoIYAAAgAElEQVSnX79+EfuMmJ7ePCMDhg+H/AGhBw/CiBEQF2drdZuKz19vGhObwtH8ENMljFGjjgSLfHv3uv3GVGTx8fHk5OSE5SZhKj5VJScnh/j4+JDOE9MljHXrgttvTEXRokULsrOzCfeknKbiio+Pp0WLFiGdI6YDRsuW4KsLeMuWZZ8XY8KpWrVqBSOMjQmXmK6SGjsWatUqvK9WLbffGGNMYTEdMAYOdGt1JyS4FfUSEtxra/A2xpijxXSVFLjgYAHCGGNKVmlGeovIFqD4SWmK1xjYGqbsVDR27bErlq8/lq8djlx/gqoGtAJdpQkYoRKRBYEOj69s7Npj89ohtq8/lq8dSnf9Md2GYYwxJnAWMIwxxgTEAsYRk6OdgSiya49dsXz9sXztUIrrtzYMY4wxAbEShjGlICJZInJBtPNhTFmygGGMMSYgMR8wRKSniKwUkdUiMjLa+Slrnl/KP4jIEhEJ/6rx5YiITBGR30TkR699x4jIJyKyyvPYMMTPuMHzb2mbiMwSkeM9+0VEJng+P1dEMkUkyfPexSKyXER2icgGEbk7tCv1mzdf1z/a85lLPNvFkfjsaBORE0RkroisEJFlInK7Z39Yv//yqJhrD/q7j+mAISJVgElAL6AdMEBE2kU3V1FxrqqmxkCf9FeAnkX2jQQ+U9WTgM88r0tFRM4DHgX+CDTDDSSd7nm7B3AOcDLQALgKyPG89zLwJ1WtCyQBn5c2DyV4haOvH2CC5/tPVdXZEfrsaMsD7lLVtsAZwM2e/+th+/7LMX/XDkF+9zEdMIDOwGpV/UVVD+D+c/eOcp5MhKjqV8C2Irt7A9M8z6cBl4fwEQOBKaq6SFV/B+4DuohIInAQqAuciutsskJVN3mOOwi0E5F6qrpdVReFkAe//Fx/TFDVTfl/V1XdBawAmhPe779cKubagxbrAaM5sN7rdTal/ENWYAp8LCILRWR4tDMTBcfl37g9j8eGcK7j8ZqeRlV340oRzVX1c+A5XIl2s4hMFpF6nqRXAhcDa0XkSxHpEkIeSuMWTxXZlMpYJVOUJ4B3BL4jvN9/uVfk2iHI7z7WA4av9StjrZ/xWaqahquWu1lEzol2hiqwjUBC/gsRqQ00AjYAqOozqtoJaI+rmvqLZ/98Ve2Nu1m9C8wowzw/D7QGUoFNwJNl+NllTkTqAO8Af1bVndHOT1nyce1Bf/exHjCygRO8XrfA/aePGaq60fP4GzATV00XSzaLSDMAz+NvQRxbTUTi8zfcjX6IiKSKSA3gEeA7Vc0SkdNE5HQRqQbsAfYDh0SkuogMFJH6qnoQ2AkcCusVFkNVN6vqIVU9DLxIJf7+PX/7d4AMVf23Z3co33+F4evaS/Pdx3rAmA+cJCKtRKQ60B+YFeU8lRkRqS0idfOf4xpmfyz+qEpnFnCd5/l1wHtBHDsb2Oe1nQ08iPuPuQn3662/J2093H/K7bhqqxxgvOe9a4AsEdkJjAAGlfJagpZ/s/S4gkr6/YuI4DoXrFDVp7zeCuX7rxD8XXtpvvuYH+nt6Uo2EaiCa7CMmfX2ROREXKkC3Noo/6rM1y8ibwDdcdM6bwYe4kgVUEtgHdBPVStlw7Cf6++Oq5JQIAvXW2uT7zNUXCLSFfga+AE47Nl9P64uv1J//8Vc+wCC/O5jPmAYY4wJTKxXSRljjAmQBQxjjDEBsYBhjDEmIFWjnYFwady4sSYmJkY7G8YYU6EsXLhwa6BreleagJGYmMiCBZV67jxjjAk7EVlbcion5qukMjIgMRHi4txjRka0c2SMMeVTRANGSVOHi0gNEXnT8/53nnlOEJFqIjJN3LTbK0TkvkjkLyMDbrgB1q4FVfc4fLgFDWOM8SViASPAqcOvB7arahtgAvC4Z38/oIaqdgA6AX/KDybhNGoU7NtXeN/evW6/McaYwiLZhlEwdTiAiORPHb7cK01vYLTn+dvAc55h7ArUFpGqQE3gAG6OnbBaty64/caYIw4ePEh2djb79++PdlZMAOLj42nRogXVqlUr9TkiGTB8TR1+ur80qponIrm42T3fxgWTTUAt4A5fw/U903EPB2jZsmXQGWzZ0lVD+dpvjClednY2devWJTExEfc7z5RXqkpOTg7Z2dm0atWq1OeJZBtGIFOH+0vTGTdj5/FAK+Auz7xHhROqTlbVdFVNb9IkoF5hhYwdC7VqFd5Xo4bbb4wp3v79+2nUqJEFiwpARGjUqFHIpcFIBoxApg4vSOOpfqqPWxHsauAjVT3omXb7GyDsy4cOHAiTJ0OCZwWDKlWgWTPo37/444wxjgWLiiMc31UkA0YgU4d7Ty3cF/hc3WyI64DzxKmNW4f2f5HI5MCBkJXlekm9/rp7/vLLkfgkY4yp2CIWMFQ1D7gFmINbQ3aGqi4TkTEicpkn2ctAIxFZDdzJkQXYJwF1cPOzzwemqmpmpPKa76qroFs3uO8+yMmJ9KcZE1vCPeYpJyeH1NRUUlNTadq0Kc2bNy94feDAgYDOMWTIEFauXFlsmkmTJpERpr72Xbt2ZcmSJWE5VzREdKS3qs7GLTLjve+vXs/347rQFj1ut6/9kSYCzz4LHTvCgw/CP/5R1jkwpnLKyHBjnPbuda/zxzyBK+WXRqNGjQpuvqNHj6ZOnTrcfffdhdKoKqpKXJzv38ZTp04t8XNuvvnm0mWwEor5kd5FdegAN98ML7wAixdHOzfGVA6jRh0JFvkiNeZp9erVJCUlMWLECNLS0ti0aRPDhw8nPT2d9u3bM2bMmIK0+b/48/LyaNCgASNHjiQlJYUuXbrw229utdYHHniAiRMnFqQfOXIknTt35pRTTuHbb78FYM+ePVx55ZWkpKQwYMAA0tPTSyxJvP7663To0IGkpCTuv/9+APLy8rjmmmsK9j/zzDMATJgwgXbt2pGSksKgQWW2IONRLGD48PDD0KgR3Hqra9swxoSmrMc8LV++nOuvv57FixfTvHlzHnvsMRYsWMDSpUv55JNPWL58+VHH5Obm0q1bN5YuXUqXLl2YMmWKz3OrKt9//z1PPPFEQfB59tlnadq0KUuXLmXkyJEsLuHXZnZ2Ng888ABz585l8eLFfPPNN3zwwQcsXLiQrVu38sMPP/Djjz9y7bXXAjBu3DiWLFnC0qVLee6550L865SeBQwfGjSAxx6Db76xaUKMCQd/Y5siNeapdevWnHbaaQWv33jjDdLS0khLS2PFihU+A0bNmjXp1asXAJ06dSIrK8vnufv06XNUmnnz5tHf070yJSWF9u3bF5u/7777jvPOO4/GjRtTrVo1rr76ar766ivatGnDypUruf3225kzZw7169cHoH379gwaNIiMjIyQBt6FygKGH4MHQ+fO8Je/wM6wjzE3Jrb4GvNUq1bkxjzVrl274PmqVat4+umn+fzzz8nMzKRnz54+xyNUr1694HmVKlXIy8vzee4aNWoclSbYpa79pW/UqBGZmZl07dqVZ555hj/96U8AzJkzhxEjRvD999+Tnp7OoUOHgvq8cLGA4UdcHDz3HGzeDF5VnsaYUvAe8yTiHidPLn2DdzB27txJ3bp1qVevHps2bWLOnDlh/4yuXbsyY8YMAH744QefJRhvZ5xxBnPnziUnJ4e8vDymT59Ot27d2LJlC6pKv379ePjhh1m0aBGHDh0iOzub8847jyeeeIItW7awt2iDUBmpNOthRMJpp8H118PTT7vHtm2jnSNjKq6BA8smQBSVlpZGu3btSEpK4sQTT+Sss84K+2fceuutXHvttSQnJ5OWlkZSUlJBdZIvLVq0YMyYMXTv3h1V5dJLL+UPf/gDixYt4vrrr0dVEREef/xx8vLyuPrqq9m1axeHDx/m3nvvpW7dumG/hkBIsEWp8io9PV0jsYDSli1w8smQng4ff+x+HRljYMWKFbS1X1GA692Ul5dHfHw8q1atokePHqxatYqqVcvXb3Jf35mILFTVgGbSKF9XUw41aQJ/+5vrMfXvf8OVV0Y7R8aY8mb37t2cf/755OXloaq88MIL5S5YhEPlu6IIGDECXnwR7rwTevU6uvHOGBPbGjRowMKFC6OdjYizRu8AVK3qRoCvW+e62xpjTCyygBGgc86Bq6+GcePgl1+inRtjjCl7FjCCMG6ce0xKCt8EasYYU1FYG0YQvvgCDh+G3393r8MxgZoxxlQUVsIIwqhRcPBg4X2RmkDNGFO87t27HzUIb+LEidx0003FHlenTh0ANm7cSN++ff2eu6Ru+hMnTiw0gO7iiy9mx44dgWS9WKNHj2b8+PEhnycSLGAEoawnUDPG+DdgwACmT59eaN/06dMZMGBAQMcff/zxvP3226X+/KIBY/bs2TRo0KDU56sIrEoqCC1bumooX/uNiWV//jOEe12g1FTwzCruU9++fXnggQf4/fffqVGjBllZWWzcuJGuXbuye/duevfuzfbt2zl48CB///vf6d27d6Hjs7KyuOSSS/jxxx/Zt28fQ4YMYfny5bRt25Z9+/YVpLvxxhuZP38++/bto2/fvjz88MM888wzbNy4kXPPPZfGjRszd+5cEhMTWbBgAY0bN+app54qmO122LBh/PnPfyYrK4tevXrRtWtXvv32W5o3b857771HzZo1/V7jkiVLGDFiBHv37qV169ZMmTKFhg0b8swzz/DPf/6TqlWr0q5dO6ZPn86XX37J7bffDrjlWL/66quwjwi3EkYQfE2gBuCnVGuMiaBGjRrRuXNnPvroI8CVLq666ipEhPj4eGbOnMmiRYuYO3cud911V7ETBD7//PPUqlWLzMxMRo0aVWhMxdixY1mwYAGZmZl8+eWXZGZmctttt3H88cczd+5c5s6dW+hcCxcuZOrUqXz33Xf897//5cUXXyyY7nzVqlXcfPPNLFu2jAYNGvDOO+8Ue43XXnstjz/+OJmZmXTo0IGHH34YgMcee4zFixeTmZnJP//5TwDGjx/PpEmTWLJkCV9//XWxgai0rIQRhPyG7VGjXDVUixaut9RLL8Gf/gQnnRTd/BkTLcWVBCIpv1qqd+/eTJ8+veBXvapy//3389VXXxEXF8eGDRvYvHkzTZs29Xmer776ittuuw2A5ORkkpOTC96bMWMGkydPJi8vj02bNrF8+fJC7xc1b948rrjiioIZc/v06cPXX3/NZZddRqtWrUhNTQWKn0Id3PocO3bsoFu3bgBcd9119OvXryCPAwcO5PLLL+fyyy8H4KyzzuLOO+9k4MCB9OnThxYtWgTyJwyKlTCCNHAgZGW53lLr1sGXX7qBfZdfDrt2RTt3xsSWyy+/nM8++4xFixaxb98+0tLSAMjIyGDLli0sXLiQJUuWcNxxx/mc0tyb+Jgobs2aNYwfP57PPvuMzMxM/vCHP5R4nuJKMvlTo0PxU6iX5P/+7/+4+eabWbhwIZ06dSIvL4+RI0fy0ksvsW/fPs444wz+97//lercxbGAEaKEBJgxA/73PxgyxFboM6Ys1alTh+7duzN06NBCjd25ubkce+yxVKtWjblz57LWV+Ojl3POOYcMz6CqH3/8kczMTMBNjV67dm3q16/P5s2b+fDDDwuOqVu3Lrt8/Eo855xzePfdd9m7dy979uxh5syZnH322UFfW/369WnYsCFff/01AK+99hrdunXj8OHDrF+/nnPPPZdx48axY8cOdu/ezc8//0yHDh249957SU9Pj0jAiGiVlIj0BJ4GqgAvqepjRd6vAbwKdAJygKtUNcvzXjLwAlAPOAycpqrFh/YoOe88eOIJuOsuN3XIffdFO0fGxI4BAwbQp0+fQj2mBg4cyKWXXkp6ejqpqamceuqpxZ7jxhtvZMiQISQnJ5Oamkrnzp0Bt3pex44dad++/VFTow8fPpxevXrRrFmzQu0YaWlpDB48uOAcw4YNo2PHjsVWP/kzbdq0gkbvE088kalTp3Lo0CEGDRpEbm4uqsodd9xBgwYNePDBB5k7dy5VqlShXbt2BasHhlPEpjcXkSrAT8CFQDYwHxigqsu90twEJKvqCBHpD1yhqleJSFVgEXCNqi4VkUbADlX1u8xUpKY3D5Sqq66aPh1mz4aePaOWFWPKhE1vXvGEOr15JKukOgOrVfUXVT0ATAd6F0nTG5jmef42cL64isQeQKaqLgVQ1ZzigkV5IOIav5OTYcAA+PnnaOfIGGPCK5IBozmw3ut1tmefzzSqmgfkAo2AkwEVkTkiskhE7vH1ASIyXEQWiMiCLVu2hP0CglWrFsyc6XpOXX457N4d7RwZY0z4RDJg+Fqbrmj9l780VYGuwEDP4xUicv5RCVUnq2q6qqY3adIk1PyGRatWrlpq+XK3rKs1gpvKrLKs2BkLwvFdRTJgZAMneL1uAWz0l8bTblEf2ObZ/6WqblXVvcBsIC2CeQ2rCy90jd8zZrjGcGMqo/j4eHJycixoVACqSk5ODvHx8SGdJ5K9pOYDJ4lIK2AD0B+4ukiaWcB1wH+AvsDnqqoiMge4R0RqAQeAbsCECOY17O6+GxYscD2mtm1zpY5169w0ImPH2uy2puJr0aIF2dnZlIfqYFOy+Pj4kAfzRayXFICIXAxMxHWrnaKqY0VkDLBAVWeJSDzwGtARV7Lor6q/eI4dBNyHq6Karao+2zHyRbuXlC979kDbtrB+feH9tWrB5MkWNIwx0RdML6mIBoyyVB4DBkDz5rCxaEUcbsBfKbplG2NMWIW9W62ItPYMskNEuovIbSJSuefxDZNNm3zvtynRjTEVTaCN3u8Ah0SkDfAy0Ar4V8RyVYn4m/rcpkQ3xlQ0gQaMw55xElcAE1X1DqBZ5LJVefiaEl0EbrwxOvkxxpjSCjRgHBSRAbgeTR949lWLTJYql4EDXQN3QoILFE2bQr168Mgj8Nln0c6dMcYELtCAMQToAoxV1TWerrKvRy5blYv3lOibNkFmJpxwgptvatq0Eg83xphyIaCAoarLVfU2VX1DRBoCdYvOPGsC17IlfPMNdOsGgwfD6NE2ItwYU/4F2kvqCxGpJyLHAEuBqSLyVGSzVrnVr+9mtR08GB5+GK67Dg4ciHaujDHGv0CrpOqr6k6gDzBVVTsBF0QuW7GhenWYMgXGjIHXXnNVVNu3RztXxhjjW6ABo6qINAP+yJFGbxMGIvDggy5gzJsHZ53l2jsyMiAx0c18m5joXhtjTDQFOpfUGGAO8I2qzheRE4FVkctW7Bk0CFq0gCuugNRU2L8ffv/dvbd2LQwf7p7bdCLGmGixqUHKmRUroEMHOORjuSibTsQYE26RmBqkhYjMFJHfRGSziLwjIqFNe2h8atvWd7AAm07EGBNdgbZhTMVNRX48bpW89z37TAQkJPjeb9OJGGOiKdCA0URVp6pqnmd7BSgfS9xVQr6mEwFIT4eDB8s+P8YYA4EHjK0iMkhEqni2QUBOJDMWy4pOJ9KiBXTpAu+84x6XLYt2Do0xsSjQgDEU16X2V2ATbnW8IZHKlCk8ncj69fDtt/D2267HVFoaPP445OVFO5fGmFgS6NQg61T1MlVtoqrHqurluEF8pgxdeaUrXVx6KYwcCV27wsqV7j0bt2GMibRASxi+3Bm2XJiAHXssvPUW/Otf8NNPbszGwIFwww2u9KF6ZNyGBQ1jTDiFEjAkbLkwQRGBAQNcaePCC13w2LevcJq9e2HUqOjkzxhTOYUSMEoc8SciPUVkpYisFpGRPt6vISJvet7/TkQSi7zfUkR2i8jdIeSz0mrWDN57z//7Nm7DGBNOxQYMEdklIjt9bLtwYzKKO7YKMAnoBbQDBohIuyLJrge2q2obYALweJH3JwAfBnE9MUfE/7iNE04o27wYYyq3YgOGqtZV1Xo+trqqWtI8VJ2B1ar6i6oeAKYDvYuk6Q3kLyH0NnC+iAiAiFwO/AJYJ9IS+Bu38fvv8Prr/keOG2NMMEKpkipJc2C91+tszz6faTxrhucCjUSkNnAv8HBxHyAiw0VkgYgs2LJlS9gyXtEUHbfRsiXccQccdxxccw0kJcGbb7ouusYYU1qRDBi+GsWLtnv4S/MwMEFVdxf3Aao6WVXTVTW9SZPYHnjuPW5j7Vp46ilYvNj1qIqLg/79ISXFDf7LDxzWFdcYE4xIBoxswLsWvQWw0V8aEakK1Ae2AacD40QkC/gzcL+I3BLBvFZKcXHQt69bQ/yNN9y0In37QqdOcOed1hXXGBOcSAaM+cBJItJKRKoD/XETGHqbBVzned4X+Fyds1U1UVUTgYnAI6r6XATzWqlVqeJKGMuWwauvwq5dMGGCdcU1xgQnYgHD0yZxC27hpRXADFVdJiJjROQyT7KXcW0Wq3EDAY/qemvCp0oV16bxv//5T2NdcY0x/kSyhIGqzlbVk1W1taqO9ez7q6rO8jzfr6r9VLWNqnZW1V98nGO0qo6PZD5jTdWq/rvi1qwJc+b471ll7R7GxK6IBgxTfvnqilu1qgsEPXu6YPDgg/Dzz0fez8hw7RzW7mFMbLKAEaOKdsVNSIBXXoGtW13Pqg4d4JFHoE0bOPdc1/Zx332uncObtXsYEztsTW/j14YNLlBMmQKrV/tPJ2JjPIypqMK+preJTc2bu1LFTz/BV19B7dq+07UoZnV3a/MwpvKwgGFKJAJnnw0vvOAaxYvauBG6dXOLOmVmuvYNsDYPYyobq5IyQcnIcG0W69a5yQ2vvdb1qPrwQ1iyxKVp3tw1nM+aBb5mbElIcKPSjTHRF0yVlAUMEzYbN8JHH7ng8fHHsHOn73QltXl4B6WWLV2ProEDI5NnY2KdBQwTdQcPuhLI5s1Hv1e9OgwbBl26uO3EE10QgSPVWN69sWrVcj26LGgYE37W6G2irlo1ePJJ32M92rRxva+uucY9P+44uOwy1433rrtK13XXGteNibyS1rQwptTySwS+qpcOHXJzW/3nP/Df/7rH99/3f661a/2/V7RUkt+47p0HY0zorErKlBvbtkHbtvDbb77fb9rUDShMTnaPHTpAu3Zw6qm+A0pxjevWTmKMY1VSpkI65hi3jkfRaqwaNeDqq+GiiyAnByZNgsGD3TTttWv7L334m0ixtN19rdrLxDorYZhyp6Rf/4cOuZHnmZnwww8wfvzRU7WDm533rLPgpJPcdvLJ7vHii2H9+qPTl1QiscZ4UxlZLykTU3zdzKtVgzPOcN13V63yX81VVHY2NGvmShHeEhODr/bKz5tVfZnyzKqkTEzxNZHi1KluOpN581zX3h07YP58+Ne/oH59/+dq0cKNZm/TBs4/H4YOhTFjgq/2gtJVfVm1lynPrIRhYo6vEkl8PNxyixsTkpXlbu5r17rnv/7q/1w1a7rR7s2bu+34448879jRd0DxVyopbbWXlWJMKIIpYaCqlWLr1KmTGhOo119XTUhQFXGPr7/uP+2+farjx6vWqKHqygpui4tTbdlStXHjwvsD2WbNUv3uO9W1a1X373efk5DgO21CQvHXUatW4fS1ahV/PcFev6ncgAUa4H026jf6cG0WMEykFXeT3b9f9ZdfVOfNU33zTdWnnlKtVy/wAFK/fvHvf/65amam6qZNqgcOHPncsgoyFmAqr2AChlVJGRMhvqqYataERx+FM890bSu//uoeN2+Gl18+epS7P/XrQ5Mmxa9T8tln0KiR6658zDGueksk+AZ8qyqr3KxKyphyIphf5r5++desqfrYY6pz56q+9Zbq88+rjhmjetttqgMGqMbHB16KqV5dtWnT4tNMm6b63nuqX37pSjTr1qmecELZlGKC/XuVJr05GuWlhCEiPYGngSrAS6r6WJH3awCvAp2AHOAqVc0SkQuBx4DqwAHgL6r6eXGfZSUMUxkE+6vcXwP+Qw+5iR23bXNbTs6R5xkZgZdkSnLtta60U78+1Kt35Pltt/nuyhzOsS5W8gmPclHCwAWJn4ETcTf+pUC7ImluAv7ped4feNPzvCNwvOd5ErChpM+zEoaJVaX5Ve6rJPPPf6quXq26YIHqp5+6Es2LL6o2aOC7hFGtmvu8Bg1cB4BASzpNm6qedJJqWppq9+6ql16qevXVqnXq+E7fpInqF1+4fK1cqbphg2purutwUF5LPqU9JhooD43eQBdgjtfr+4D7iqSZA3TxPK8KbMXT1dcrjeBKHzWK+zwLGMYELtSqsqI32cOHVXftUs3OVl22zH/VV716qjfcoNq/v+rFF6uefbZqaqrqiScGHnAC2Xr3dkHohhtU//xn1VGjVB99VLVhQ9/pmzVT/fln16kgN1f14MHgrr80f7NQvpNQjikqmIARsSopEekL9FTVYZ7X1wCnq+otXml+9KTJ9rz+2ZNma5HzjFDVC3x8xnBgOEDLli07rS1uSlNjTKmFo6qspOoif43xTZu68+3aBbt3H9n+9jfIzT06fY0acMopsGeP23bvdo/B3uqqV3d53rXLTUdTVK1a0K+fe6xZs/Dj3/7mqv+KatYM5s511YY1ax7Z3nwz+L9XuKarKRdTg4hIP+CiIgGjs6re6pVmmSeNd8DorKo5ntftgVlAD1X9ubjPszYMY8qXSAeZYNKrwv79bj6x7Oyjz9W4sZuTbO9et+3Zc+T5s8/6z3PLli7Nvn3uMdy30+rVXVtUzZouyOQHmvh4eP11F8yKCnYJ5GACRiTXw8gGTvB63QLY6CdNtohUBeoD2wBEpAUwE7i2pGBhjCl/Bg4M7pduceunhJpexN1oH3vMd5CZONH/58yaFVg3ZFU4cMCdu0MH2LDh6GOaNHGftW+f2/bvd49//avvzz5wwJ1327Yj6fM3X8ECip+uJmSB1l0Fu+GC0S9AK440ercvkuZmCjd6z/A8b+BJf2Wgn2dtGMaYQISjk0C42zBKMwCzNMf4Qnlo9Hb54GLgJ1xvqVGefWOAyzzP44G3gNXA98CJnv0PAHuAJV7bscV9lgUMY0ykRLpBuqwa1oD+s1EAAAU+SURBVH0JJmDYSG9jjCkHSjM+JBxjSspFo3dZs4BhjDHBi8mAISJbgFD61TbGjQOJRXbtsSuWrz+Wrx2OXH+CqjYJ5IBKEzBCJSILAo2ylY1de2xeO8T29cfytUPprt9W3DPGGBMQCxjGGGMCYgHjiMnRzkAU2bXHrli+/li+dijF9VsbhjHGmIBYCcMYY0xALGAYY4wJSMwHDBHpKSIrRWS1iIyMdn7KmohkicgPIrJERCr1yEcRmSIiv3mm1c/fd4yIfCIiqzyPDaOZx0jyc/2jRWSD5/tfIiIXRzOPkSIiJ4jIXBFZISLLROR2z/5K//0Xc+1Bf/cx3YYhIlVwc11diJs5dz4wQFWXRzVjZUhEsoB09VqDpLISkXOA3cCrqprk2TcO2Kaqj3l+MDRU1Xujmc9I8XP9o4Hdqjo+mnmLNBFpBjRT1UUiUhdYCFwODKaSf//FXPsfCfK7j/USRmdgtar+oqoHgOlA7yjnyUSIqn6FZ/p8L72BaZ7n03D/kSolP9cfE1R1k6ou8jzfBawAmhMD338x1x60WA8YzYH1Xq+zKeUfsgJT4GMRWehZwTDWHKeqm8D9xwKOjXJ+ouEWEcn0VFlVuiqZokQkEegIfEeMff9Frh2C/O5jPWCIj32xVkd3lqqmAb2Amz3VFiZ2PA+0BlKBTcCT0c1OZIlIHeAd4M+qujPa+SlLPq496O8+1gNGIKsCVmqqutHz+BtuhcPO0c1RmdvsqePNr+v9Lcr5KVOqullVD6nqYeBFKvH3LyLVcDfMDFX9t2d3THz/vq69NN99rAeM+cBJItJKRKrjVv2bFeU8lRkRqe1pBENEagM9gB+LP6rSmQVc53l+HfBeFPNS5vJvlh5XUEm/fxER4GVghao+5fVWpf/+/V17ab77mO4lBeDpSjYRqAJMUdWxUc5SmRGRE3GlCnBL6v6rMl+/iLwBdMdN67wZeAh4F5gBtATWAf1UtVI2DPu5/u64KgkFsoA/5dfpVyYi0hX4GvgBOOzZfT+uLr9Sf//FXPsAgvzuYz5gGGOMCUysV0kZY4wJkAUMY4wxAbGAYYwxJiAWMIwxxgTEAoYxxpiAWMAwpgQicshrRs8l4ZzVWEQSvWePNaY8qxrtDBhTAexT1dRoZ8KYaLMShjGl5FlL5HER+d6ztfHsTxCRzzyTun0mIi09+48TkZkistSznek5VRURedGzVsHHIlLTk/42kf9v7+5ZowqiOIw/RxEJiApaKqRJJSi+4AewtbQIYiVpTKOVLx/AXgimsbAQBcuUARERRLEQ0mgpdgpJESRNEPlb3FEX3XUvick2z6/Zc88uw0517tzZnVMf2jhPJzRN6RcLhjTe1B+PpGYH3vua5Dxwn+7EAFr8KMlJ4Amw0PILwMskp4AzwPuWnwEWk5wA1oFLLX8HON3GubZTk5P68p/e0hhVtZHkwJD8J+BCko/tcLcvSY5U1Rpdw5pvLf85ydGqWgWOJdkcGGMaeJZkpl3fBvYluVtVy3QNj5aApSQbOzxV6Z9cYUjbkxHxqM8MszkQf+f33uJFYBE4C7yrKvccNVEWDGl7Zgde37T4Nd3JxwBXgFctfg7MQ9ceuKoOjhq0qvYAx5O8AG4Bh4G/VjnSbvKORRpvqqpWBq6Xk/z8ae3+qnpLd/N1ueWuAw+r6iawClxt+RvAg6qao1tJzNM1rhlmL/C4qg7RNfq6l2T9v81I2gL3MKQtansY55KsTfq7SLvBR1KSpF5cYUiSenGFIUnqxYIhSerFgiFJ6sWCIUnqxYIhSerlB28kbc0knGBaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy.\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(list(range(25)), acc, 'bo', label='Training accuracy')\n",
    "plt.plot(list(range(25)), val_acc, 'b', label='Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss.\n",
    "plt.subplot(212)\n",
    "plt.plot(list(range(25)), loss, 'bo', label='Training loss')\n",
    "plt.plot(list(range(25)), val_loss, 'b', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Judging by the slope of the accuracy and loss progressions it appears that even after 25 epochs the network is still able to perform better even though very slowly from this point onwards. Overfitting has not yet been reached and we end up with an accuracy of around 85%. \n",
    "\n",
    "The network still has room for improvement. Notably using a different cost function, such as cross entropy, might make the network learn faster. Regularization and convolutional layers would also help. A disappointment to me was that the network did not run when using relus due to division by zero, which is an issue I have yet to fix. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
